# -*- coding: utf-8 -*-
"""Digits Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NoEVLu3mCszDWgndcJaQopSd8ztHT2KZ
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

#loading the data into train and test 
(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()

#lets know the size 
x_train[0].shape

#lets see some samples
plt.imshow(x_train[0])

x_train.shape

y_train

#scalling to improve the accuracy
x_train=x_train/255
x_test=x_test/255

##flatening( optional )
#x_train_flat=x_train.reshape(len(x_train),28*28)
#x_test_flat= x_test.reshape(len(x_test),28*28)

x_train_flat

#create a neutal network
model=keras.Sequential([
                        keras.layers.Flatten(input_shape=(28,28)),
                        keras.layers.Dense(400,activation='relu'),
                        keras.layers.Dense(100,activation='relu'),
                        keras.layers.Dense(10,activation='sigmoid')
])
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
model.fit(x_train,y_train,epochs=10)        # if we use flatening then model.fit(x_train_flat,y_train,epochs=10)

model.evaluate(x_test,y_test)

#alculating y_predicted
y_pre=model.predict(x_test)                       #if we use the above flatening optional then y_pre=model.predict(x_test_flat)

y=[np.argmax(element) for element in y_pre]

for i in range (5):
  #y=[np.argmax(i) for element in y_pre]
  plt.matshow(x_test[i])
  plt.xlabel(y[i])

y[:5]

